{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "## What are neural networks?\n",
    "A neural network is a machine learing training algorithm which is loosely based on the working of the human brain. A neural network has input nodes where we pass feature values which are passed through layers after which we give the output in terms of output nodes.\n",
    "<img src=\"neural_nets.png\" height=600 width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "In neural networks, an activation function refers to the function that is applied on the data when it is passed forward. It is the computation that occurs due to which information is carried forward in the neural network.\n",
    "<img src=\"activation-functions.png\" height=600 width=600>\n",
    "<img src=\"activation-function.png\" height=600 width=600>\n",
    "\n",
    "## Weights\n",
    "Weights basically tell us **how important a particular feature is for the model**. A neural network learns on the basis of these weights. The values assigned to each weight is random initially. We usually have it in the form of a matrix or a vector. We will discuss how it changes soon.\n",
    "\n",
    "## Input Layer\n",
    "This is the layer where we input the signals or features or in even simpler terms, the input layer is **X**. We pass in values to this layer after which, the network passes them forward.\n",
    "\n",
    "## Hidden Layers\n",
    "These are the layers where the magic happens. They basically have nodes where activation functions are applied. On applying these functions, we get outputs which are passed on to further nodes.\n",
    "\n",
    "## Output Layer\n",
    "This is the final layer in the neural network model. The output is calculated or shown in this layer. We get the output in the form of a continuous value or a class depending on the task at hand.\n",
    "\n",
    "## Forward Propagation\n",
    "Also known as forward pass, this is the process of passing the data forward through the neural network to get an output for that layer. It is also referred to as inference.\n",
    "\n",
    "## Backpropagation\n",
    "Possibly the most important topic in this topic, backpropagation is the process of checking the error or the distance between the the output you obtained and the output that is expected of the network. It does this by finding the partial derivative of the output function. This is done for every set of weights. The forward pass then occurs again with the newly updated weights which should produce an output closer to the actual expected output. This processes is repeated for a certain number of iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks from Scratch\n",
    "The following section is a simple implementation to understand how neural networks work. The code is based on the VTU machine learning lab. I'd like to thank [Praahas Amin](https://github.com/praahas) for [his work](https://github.com/praahas/machine-learning-vtu) on it and would like to thank him for letting me use his code for the purpose of this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T16:10:51.227046Z",
     "start_time": "2019-09-30T16:10:51.219810Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T16:11:47.118421Z",
     "start_time": "2019-09-30T16:11:47.095053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16315786, 0.34687718],\n",
       "       [0.52440762, 0.29383145],\n",
       "       [0.81306845, 0.06814426]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize values\n",
    "X = np.random.rand(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T16:11:55.401186Z",
     "start_time": "2019-09-30T16:11:55.376143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94500291],\n",
       "       [0.69429435],\n",
       "       [0.11578679]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.random.rand(3, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T16:10:51.637618Z",
     "start_time": "2019-09-30T16:10:51.635117Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Divide each element of X by an array with max of each column\n",
    "# X = X / np.max(X, axis=0) \n",
    "# # Divide each element of y by 100\n",
    "# y = y / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T16:10:52.066043Z",
     "start_time": "2019-09-30T16:10:52.056398Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  # The np.exp works like e^x where e is eulers constant \n",
    "\n",
    "def sigmoid_derive(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T16:10:52.205037Z",
     "start_time": "2019-09-30T16:10:52.199438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize values\n",
    "epoch=7000\n",
    "learning_rate = 0.2\n",
    "input_nodes = 2\n",
    "hidden_nodes = 3 \n",
    "output_nodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T16:10:52.572317Z",
     "start_time": "2019-09-30T16:10:52.557495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Weight of hidden layer\n",
    "wh = np.random.uniform(size = (input_nodes, hidden_nodes))\n",
    "# Weight of output layer\n",
    "wo=np.random.uniform(size = (hidden_nodes, output_nodes)) \n",
    "\n",
    "# Bias of hidden layer\n",
    "bh = np.random.uniform(size = (1, hidden_nodes))\n",
    "# Bias of output layer\n",
    "bo=np.random.uniform(size = (1, output_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T16:10:53.215999Z",
     "start_time": "2019-09-30T16:10:52.922975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -> 0, learning_rate -> 0.2, error_rate -> [8.7311097e-08]\n",
      "Epoch -> 1000, learning_rate -> 0.2, error_rate -> [1.43336664e-06]\n",
      "Epoch -> 2000, learning_rate -> 0.2, error_rate -> [6.85124874e-09]\n",
      "Epoch -> 3000, learning_rate -> 0.2, error_rate -> [3.68031818e-08]\n",
      "Epoch -> 4000, learning_rate -> 0.2, error_rate -> [3.83261085e-08]\n",
      "Epoch -> 5000, learning_rate -> 0.2, error_rate -> [3.01310567e-08]\n",
      "Epoch -> 6000, learning_rate -> 0.2, error_rate -> [2.18222444e-08]\n"
     ]
    }
   ],
   "source": [
    "# Training starts\n",
    "for i in range(epoch):\n",
    "    #Forward Propogation\n",
    "    net_h = np.dot(X, wh) + bh  #net_h = net input for hidden layer\n",
    "    \n",
    "    sigma_h = sigmoid(net_h)  #sigma_h = output of sigmoid function of hidden layer\n",
    "    \n",
    "    net_o = np.dot(sigma_h, wo) + bo  #net_o = net input for output layer\n",
    "    \n",
    "    output = sigmoid(net_o)  #output = is the output of output layer i.e sigmoid of net_o\n",
    "    \n",
    "    #Backpropagation\n",
    "    \n",
    "    deltaK = (y - output) * sigmoid_derive(output)  ##calculate deltak\n",
    "    \n",
    "    deltaH = deltaK.dot(wo.T) * sigmoid_derive(sigma_h)  #deltaH\n",
    "    \n",
    "    wo = wo + sigma_h.T.dot(deltaK) * learning_rate  #Update output layer weights\n",
    "    \n",
    "    wh = wh + X.T.dot(deltaH) * learning_rate  #Update hidden layer weights\n",
    "    error = sum(deltaK) ** 2 / len(deltaK)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Epoch -> {i}, learning_rate -> {learning_rate}, error_rate -> {error}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T16:10:25.758780Z",
     "start_time": "2019-09-30T16:10:25.741960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "[[0.08894989 1.        ]\n",
      " [1.         0.82233848]\n",
      " [0.30251951 0.84390054]]\n",
      "Actual Output: \n",
      "[[0.00053973]\n",
      " [0.00211195]\n",
      " [0.00311097]]\n",
      "Predicted Output: \n",
      " [[0.00865435]\n",
      " [0.0064224 ]\n",
      " [0.00883296]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\" + str(X))\n",
    "print(\"Actual Output: \\n\" + str(y))\n",
    "print(\"Predicted Output: \\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
